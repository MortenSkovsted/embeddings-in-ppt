{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = torch.load('../hpc-tensors/Best_prediction_1.pt')\n",
    "prediction = torch.cat((prediction,torch.load('../hpc-tensors/Best_prediction_2.pt')),dim=0)\n",
    "prediction = torch.cat((prediction,torch.load('../hpc-tensors/Best_prediction_3.pt')),dim=0)\n",
    "prediction = torch.cat((prediction,torch.load('../hpc-tensors/Best_prediction_4.pt')),dim=0)\n",
    "\n",
    "targets = torch.load('../hpc-tensors/Targes_1.pt')\n",
    "targets = torch.cat((targets,torch.load('../hpc-tensors/Targes_2.pt')),dim=0)\n",
    "targets = torch.cat((targets,torch.load('../hpc-tensors/Targes_3.pt')),dim=0)\n",
    "targets = torch.cat((targets,torch.load('../hpc-tensors/Targes_4.pt')),dim=0)\n",
    "\n",
    "prepredictions = torch.load('../hpc-tensors/Best_postpredictions_1.pt')\n",
    "prepredictions = torch.cat((prepredictions,torch.load('../hpc-tensors/Best_postpredictions_2.pt')),dim=0)\n",
    "prepredictions = torch.cat((prepredictions,torch.load('../hpc-tensors/Best_postpredictions_3.pt')),dim=0)\n",
    "prepredictions = torch.cat((prepredictions,torch.load('../hpc-tensors/Best_postpredictions_4.pt')),dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21504, 10])\n",
      "torch.Size([21504, 10])\n",
      "torch.Size([10, 65792])\n",
      "torch.Size([65792, 10])\n"
     ]
    }
   ],
   "source": [
    "print(prediction.size())\n",
    "print(targets.size())\n",
    "print(prepredictions.transpose(0,1).size())\n",
    "print(prepredictions.size())\n",
    "#prepredictions = prepredictions.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6598)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:,0:1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0595238095238093"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "65792/21504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred:\t6598\n",
      "Target:\t7397\n",
      "Pred:\t8483\n",
      "Target:\t7662\n",
      "Pred:\t2689\n",
      "Target:\t2615\n",
      "Pred:\t1724\n",
      "Target:\t1942\n",
      "Pred:\t2535\n",
      "Target:\t3117\n",
      "Pred:\t1161\n",
      "Target:\t1469\n",
      "Pred:\t841\n",
      "Target:\t821\n",
      "Pred:\t262\n",
      "Target:\t965\n",
      "Pred:\t94\n",
      "Target:\t1120\n",
      "Pred:\t0\n",
      "Target:\t211\n"
     ]
    }
   ],
   "source": [
    "for i in range(prediction.size()[1]):\n",
    "    print(f'Pred:\\t{prediction[:,i:i+1].sum()}')\n",
    "    print(f'Target:\\t{targets[:,i:i+1].sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4829,  5649,  2260,  1316,  1775,   573,   657,   118,    26,\n",
       "            0],\n",
       "       [12338, 11008, 18460, 19154, 17627, 19447, 20499, 20395, 20316,\n",
       "        21293],\n",
       "       [ 1769,  2834,   429,   408,   760,   588,   184,   144,    68,\n",
       "            0],\n",
       "       [ 2568,  2013,   355,   626,  1342,   896,   164,   847,  1094,\n",
       "          211]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionmatrix = np.zeros((4,10), dtype=int)\n",
    "print(confusionmatrix)\n",
    "print(prediction.size()[0] == targets.size()[0])\n",
    "\n",
    "# Make a confusionmattix that contains (in rows):\n",
    "# 1. count of number of times each positive label (1) was correctly predicted labels.\n",
    "# 2. count of number of times each negativ label (0) was correctly predicted labels. \n",
    "# 3. the number of time each label was predicted, but was not there\n",
    "# 4. the number of times each label was there, but was not predicted.\n",
    "\n",
    "# This was done of each of the 10 sublocation\n",
    "\n",
    "for i in range(prediction.size()[1]):\n",
    "    for j in range(prediction.size()[0]):\n",
    "        # 1.\n",
    "        if prediction[j,i] == 1 and targets[j,i] == 1:\n",
    "            confusionmatrix[0,i] += 1\n",
    "        # 2.\n",
    "        elif prediction[j,i] == 0 and targets[j,i] == 0:\n",
    "            confusionmatrix[1,i] += 1\n",
    "        # 3.\n",
    "        elif prediction[j,i] == 1 and targets[j,i] == 0:\n",
    "            confusionmatrix[2,i] += 1\n",
    "        elif prediction[j,i] == 0 and targets[j,i] == 1:\n",
    "            confusionmatrix[3,i] += 1\n",
    "\n",
    "confusionmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4829\t5649\t2260\t1316\t1775\t573\t657\t118\t26\t0\t\n",
      "12338\t11008\t18460\t19154\t17627\t19447\t20499\t20395\t20316\t21293\t\n",
      "1769\t2834\t429\t408\t760\t588\t184\t144\t68\t0\t\n",
      "2568\t2013\t355\t626\t1342\t896\t164\t847\t1094\t211\t\n"
     ]
    }
   ],
   "source": [
    "Highlevel_list = ['Nucleus','Cytoplasm','Extracellular','Mitochondrion','Cell membrane','Endoplasmic reticulum','Plastid','Golgi apparatus','Lysosome/Vacuole','Peroxisome']\n",
    "    \n",
    "#for j in range(len(Highlevel_list)):\n",
    "#    print(Highlevel_list[j],end='\\t')\n",
    "for i in range(4):\n",
    "    for j in range(len(Highlevel_list)):\n",
    "        print(confusionmatrix[i,j],end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4829\t5649\t2260\t1316\t1775\t573\t657\t118\t26\t0\t\n",
      "1769\t2834\t429\t408\t760\t588\t184\t144\t68\t0\t\n",
      "2568\t2013\t355\t626\t1342\t896\t164\t847\t1094\t211\t\n"
     ]
    }
   ],
   "source": [
    "Highlevel_list = ['Nucleus','Cytoplasm','Extracellular','Mitochondrion','Cell membrane','Endoplasmic reticulum','Plastid','Golgi apparatus','Lysosome/Vacuole','Peroxisome']\n",
    "    \n",
    "#for j in range(len(Highlevel_list)):\n",
    "#    print(Highlevel_list[j],end='\\t')\n",
    "for i in [0,2,3]:\n",
    "    for j in range(len(Highlevel_list)):\n",
    "        print(confusionmatrix[i,j],end='\\t')\n",
    "    print()\n",
    "\n",
    "# 1. Correctly predicted to be precent\n",
    "# 2. the number of time each label was predicted, but was not there\n",
    "# 3. the number of times each label was there, but was not predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nucleus: Cytoplasm: Extracellular: Mitochondrion: Cell membrane: Endoplasmic reticulum: Plastid: Golgi apparatus: Lysosome/Vacuole: Peroxisome: "
     ]
    }
   ],
   "source": [
    "for j in range(len(Highlevel_list)):\n",
    "\n",
    "    print(Highlevel_list[j],end=': ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_number_pred = []\n",
    "count_number_targets = []\n",
    "for loc_count in range(10):\n",
    "    count_number_pred.append(0)\n",
    "    count_number_targets.append(0)\n",
    "\n",
    "\n",
    "for i in range(prediction.size()[0]):\n",
    "    for loc_count in range(10):\n",
    "        if prediction[i].sum() == loc_count:\n",
    "            count_number_pred[loc_count] += 1\n",
    "        if targets[i].sum() == loc_count:\n",
    "            count_number_targets[loc_count] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 18621, 2883, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_number_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 16418, 4495, 471, 102, 18, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_number_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision\n",
      "0.732\t0.666\t0.840\t0.763\t0.700\t0.494\t0.781\t0.450\t0.277\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morte\\Anaconda3\\envs\\Master\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\t\n",
      "Recall\n",
      "0.653\t0.737\t0.864\t0.678\t0.569\t0.390\t0.800\t0.122\t0.023\t0.000\t\n",
      "Accuracy\n",
      "0.798\t0.775\t0.964\t0.952\t0.902\t0.931\t0.984\t0.954\t0.946\t0.990\t\n",
      "F1\n",
      "0.690\t0.700\t0.852\t0.718\t0.628\t0.436\t0.791\t0.192\t0.043\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morte\\Anaconda3\\envs\\Master\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\t"
     ]
    }
   ],
   "source": [
    "print('Precision')\n",
    "for j in range(len(Highlevel_list)):\n",
    "    print(f'{confusionmatrix[0,j]/(confusionmatrix[0,j]+confusionmatrix[2,j]):.3f}',end='\\t')\n",
    "print()\n",
    "print('Recall')\n",
    "for j in range(len(Highlevel_list)):\n",
    "    print(f'{confusionmatrix[0,j]/(confusionmatrix[0,j]+confusionmatrix[3,j]):.3f}',end='\\t')\n",
    "print() \n",
    "print('Accuracy')\n",
    "for j in range(len(Highlevel_list)):\n",
    "    Tp = confusionmatrix[0,j]\n",
    "    Tn = confusionmatrix[1,j]\n",
    "    acc = (Tp+Tn) / (confusionmatrix[:,j].sum())\n",
    "    print(f'{acc:.3f}',end='\\t')\n",
    "    \n",
    "    \n",
    "print() \n",
    "print('F1')\n",
    "for j in range(len(Highlevel_list)):\n",
    "    p = confusionmatrix[0,j]/(confusionmatrix[0,j]+confusionmatrix[2,j])\n",
    "    r = confusionmatrix[0,j]/(confusionmatrix[0,j]+confusionmatrix[3,j])\n",
    "    print(f'{2*p*r/(p+r):.3f}',end='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4829, 12338,  1769,  2568])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionmatrix[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import plot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Due to output being wrong a number of things will be done to make the right dataset ready to be analysed\n",
    "The_prediction_ = prepredictions[:21504,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21504, 10])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (65792) must match the size of tensor b (21504) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-6ac75b7627a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m#True positive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mTP_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mPredicted_with_threshold\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPredicted_with_threshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m#False positiv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (65792) must match the size of tensor b (21504) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "#make AOC graphs for all locations!!!\n",
    "#numpy.random.uniform(low=0.0, high=1.0, size=None)Â¶\n",
    "\n",
    "\n",
    "tensor_row_length = The_prediction_.size()[0]\n",
    "print(The_prediction_.size())\n",
    "\n",
    "Highlevel_list\n",
    "AOC = []\n",
    "\n",
    "def TPR(TP,FN):\n",
    "    return TP/(TP+FN)\n",
    "def Specificity(FP,TN):\n",
    "    return TN/(TN+FP)\n",
    "def FPR(FP,TN):\n",
    "    return FP/(TN+FP)\n",
    "\n",
    "for i in range(10):\n",
    "    AOC.append([Highlevel_list[i]])\n",
    "    x = []\n",
    "    y = []\n",
    "    for threshold in np.linspace(0,1,101):\n",
    "\n",
    "        Predicted_with_threshold = prepredictions[:,i] > threshold\n",
    "        #print(Predicted_with_threshold.sum())\n",
    "        Negativ_prediction_with_threshold = prepredictions[:,i] <= threshold\n",
    "        #print(Negativ_prediction_with_threshold.sum())\n",
    "        \n",
    "        #print(targets[:,i].sum())\n",
    "        #print((targets[:,i] == 0).sum())\n",
    "        \n",
    "        #True positive\n",
    "        TP_count = (Predicted_with_threshold * targets[:,i].type_as(Predicted_with_threshold)).sum().item()\n",
    "\n",
    "        #False positiv\n",
    "        FP_count = (Predicted_with_threshold * (targets[:,i] == 0).type_as(Predicted_with_threshold)).sum().item()\n",
    "        \n",
    "        #True negativ\n",
    "        TN_count = (Negativ_prediction_with_threshold * targets[:,i].type_as(Negativ_prediction_with_threshold)).sum().item()\n",
    "\n",
    "        #False negativ\n",
    "        FN_count = (Negativ_prediction_with_threshold * (targets[:,i] == 0).type_as(Negativ_prediction_with_threshold)).sum().item()\n",
    "        \n",
    "        AOC[i].append((FPR(FP_count,TN_count),TPR(TP_count,FN_count)))\n",
    "        x.append(FPR(FP_count,TN_count))\n",
    "        y.append(TPR(TP_count,FN_count))\n",
    "        \n",
    "    \n",
    "    #print(AOC[i])\n",
    "    #print(AOC[i][1:])\n",
    "    plt(x,y, '.')\n",
    "    x = [0,1]\n",
    "    y = [0,1]\n",
    "    plt(x,y)\n",
    "    break\n",
    "    #print(f'threshold = {threshold}')\n",
    "    #print(((prepredictions[i,:] < threshold).sum().item())/tensor_row_length)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_row_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(prepredictions[i,:] < threshold).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.transpose((prepredictions[i,:] < threshold),0,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(prepredictions[i,:] < threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[:,0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(prepredictions[i,:] < threshold) * targets[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(prepredictions[0,:] < 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(prepredictions[0,:] < 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.uint8(targets[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[:,0].type_as((prepredictions[0,:] < 0.5)) * (prepredictions[0,:] < 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[:,0].type_as((prepredictions[i,:] < threshold)) != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
